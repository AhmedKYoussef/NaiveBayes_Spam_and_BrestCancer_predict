{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes for predict BreastCancer diagnosis\n",
    "\n",
    "Worldwide, breast cancer is the most common type of cancer in women and the second highest in terms of mortality rates.Diagnosis of breast cancer is performed when an abnormal lump is found (from self-examination or x-ray) or a tiny speck of calcium is seen (on an x-ray). After a suspicious lump is found, the doctor will conduct a diagnosis to determine whether it is cancerous and, if so, whether it has spread to other parts of the body.\n",
    "\n",
    "This breast cancer [dataset](https://storage.googleapis.com/kaggle-datasets/56485/108594/breast-cancer-prediction-dataset.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1559393118&Signature=rw7OzcIVPYrciED4IzEPh%2BpWUPWkwAEvilsDnxwJ3%2FPnRWCCs2aI70hHaqsACJg37U0NEBpigR30Rt479ZCFmsRj9%2FiazgC2TiN%2FB7bYYr9KNJcdL35SYNDyVHZgGaO%2FZVULJXq2%2BL4Z7Z2difeZnvLgQw%2BW4aG1eL0pxKtiUJh%2FIHiwlfkDJXf3KZL1j11MZwsJ41lJXBfBEYHRNS%2FpFTXC7ifWRRsjqByJfdE7IZaEP%2BEXByeVBw8vwX0FZz%2BJ8%2Feq32EcMFo9INXVZYX4CYRVZK3V2Ik0PN8GA3Dg3DZu9MLHEJQUW9YScujQ%2BiA8idjX3lxDuPwmVWP7Qv%2FU2A%3D%3D) was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg. \n",
    "\n",
    "In this notebook I'll explain how to use naive bayes with continuous data to predict the diagnosis of breastCaner and it's a binary calssification problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bayes theorem is one of the earliest probabilistic inference algorithms developed by Reverend Bayes.\n",
    "\n",
    "* The Bayes theorem calculates the probability of an event occurring, based on certain other probabilities that are related to the event in question. It is  composed of a  prior(the probabilities that we are aware of or that is given to us) and the posterior(the probabilities we are looking to compute using the priors). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1:Understand our data\n",
    "First import pandas to read  the data from the folder \"breast-cancer-prediction-dataset/Breast_cancer_data.csv\"\n",
    "and print out the first five rows to have a quick look on the data and understand it.\n",
    "\n",
    "    As you see here there are 5 columns that will used as features input and one column called diagnosis we'll use it as label to predict beacuse our algorithm is a supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   diagnosis  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"breast-cancer-prediction-dataset/Breast_cancer_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "call `info()` method to check there is no null vakues and usnderstand the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 6 columns):\n",
      "mean_radius        569 non-null float64\n",
      "mean_texture       569 non-null float64\n",
      "mean_perimeter     569 non-null float64\n",
      "mean_area          569 non-null float64\n",
      "mean_smoothness    569 non-null float64\n",
      "diagnosis          569 non-null int64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 26.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2: Data preprocessing\n",
    "since our data is numerical and in matrix shape we don't need to preprocessing the data and now the time to\n",
    "\n",
    "## step 3: Split the data to train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>**TODO:**\n",
    "Split the dataset into a training and testing set by using the train_test_split method in sklearn. Split the data\n",
    "using the following variables:\n",
    "* `X_train` is our training data for the first 5 columns.\n",
    "* `y_train` is our training data for the 'diagnosis' column\n",
    "* `X_test` is our testing data for the first 5 columns.\n",
    "* `y_test` is our testing data for the 'diagnosis' column\n",
    "Print out the number of rows we have in each our training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 569\n",
      "Number of rows in the training set: 426\n",
      "Number of rows in the test set: 143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['mean_radius','mean_texture', 'mean_perimeter',\n",
    "                                                        'mean_area','mean_smoothness']]\n",
    "                                                    ,df['diagnosis'])\n",
    "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using sklearns `sklearn.naive_bayes` method to make predictions on our dataset. \n",
    "\n",
    "Specifically, we will be using the **Gaussian Naive Bayes** implementation. This particular classifier is suitable for classification with continuous features (such as in our case, word counts for text classification). It takes in the float numbers as its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that predictions have been made on our test set, we need to check the accuracy of our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4: Evaluating our model ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy:** measures how often the classifier makes the correct prediction. It’s the ratio of the number of correct predictions to the total number of predictions (in test dataset).\n",
    "\n",
    "**Precision** tells us the ratio of true predict to all prediction(true predict and false predict)\n",
    "\n",
    "**Recall(sensitivity)** tells us what proportion of messages that actually were spam were classified by us as spam.\n",
    "It is a ratio of true predict(words classified as spam, and which are actually spam) to all the words that were actually spam.\n",
    "\n",
    "**F1 score**, which is weighted average of the precision and recall scores. This score can range from 0 to 1, with 1 being the best possible F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9090909090909091\n",
      "Precision score:  0.9292929292929293\n",
      "Recall score:  0.9387755102040817\n",
      "F1 score:  0.934010152284264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions))) # TODO\n",
    "print('Precision score: ', format(precision_score(y_test, predictions)))# TODO\n",
    "print('Recall score: ', format(recall_score(y_test, predictions)))# TODO\n",
    "print('F1 score: ', format(f1_score(y_test, predictions)))# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 5:  let's try our model in production ! ###\n",
    "Now after we created and traind our model and tested it, it's nice to try it in our new data we insert it to understand how to use it in productions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnosis_predict(new_data):\n",
    "    a = np.asanyarray(new_data)\n",
    "    predict = model.predict(a)\n",
    "    # print the predict label (have diagnosis or not)\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 1:\n",
    "            print(\"sick\")\n",
    "        else: \n",
    "            print(\"Not sick\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can insert new data and see the predict !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sick\n",
      "sick\n",
      "Not sick\n"
     ]
    }
   ],
   "source": [
    "a= np.asarray([[7.70, 23.54, 27.92, 171.0, 0.05463],\n",
    "                  [6.30, 13.54, 37.22, 141.2, 0.01279],\n",
    "                  [16.60 ,28.08 ,108.30, 858.1, 0.08455]])\n",
    "diagnosis_predict(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Conclusion ###\n",
    "One of the major advantage it rarely ever overfits the data. Another important advantage is that its model training and prediction times are very fast for the amount of data it can handle. All in all, Naive Bayes' really is a gem of an algorithm!\n",
    "\n",
    "Congratulations! You have successfully designed a model that can  predict if an message is spam or not!\n",
    "\n",
    "Thank you for reach the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
